{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPR608Vi7AyNTPClFdUelpW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Personalización de modelos de Whisper\n"],"metadata":{"id":"nC0NXOcITR-t"}},{"cell_type":"code","source":["!pip install openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_uTRSWkOZRvu","executionInfo":{"status":"ok","timestamp":1717524274523,"user_tz":-120,"elapsed":6969,"user":{"displayName":"Arturo SP","userId":"07770316912620247459"}},"outputId":"b729fe17-7b4e-41a5-de9d-6fa60b34e17a"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.31.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.18.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.3)\n"]}]},{"cell_type":"code","source":["import os\n","os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-JgnyPrVpPr4xoz1FrPxiT3BlbkFJcIB6dz6ptu7gA5UifDsQ\"\n","print(os.environ[\"OPENAI_API_KEY\"])\n","import openai\n","openai.api_key = os.environ[\"OPENAI_API_KEY\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g_341LZcZTzN","executionInfo":{"status":"ok","timestamp":1717524275341,"user_tz":-120,"elapsed":4,"user":{"displayName":"Arturo SP","userId":"07770316912620247459"}},"outputId":"96130dc2-1421-4cc9-878e-5f3b8d32fbd5"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["sk-proj-JgnyPrVpPr4xoz1FrPxiT3BlbkFJcIB6dz6ptu7gA5UifDsQ\n"]}]},{"cell_type":"code","source":["from openai import OpenAI\n","client = OpenAI()"],"metadata":{"id":"LjvWhUrhZbX4","executionInfo":{"status":"ok","timestamp":1717524281114,"user_tz":-120,"elapsed":451,"user":{"displayName":"Arturo SP","userId":"07770316912620247459"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## Interacción con distintos modelos\n","\n","A continuación vamos a comprobar cómo podemos utilizar distintos modelos para nuestra inferencia:"],"metadata":{"id":"toUKmT8BZjBM"}},{"cell_type":"code","source":["def transcribe_audio(cliente, ruta_audio, modelo):\n","  archivo_audio = open(ruta_audio, \"rb\")\n","  transcripcion = cliente.audio.transcriptions.create(\n","      model=modelo,\n","      file=archivo_audio\n","  )\n","  return transcripcion"],"metadata":{"id":"yC42d1VuZdK8","executionInfo":{"status":"ok","timestamp":1717524290291,"user_tz":-120,"elapsed":407,"user":{"displayName":"Arturo SP","userId":"07770316912620247459"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["Hasta ahora hemos trabajado siempre con el modelo básico pero probemos unos cuántos.\n","\n","__Nota.__ No olvides subir un audio de prueba."],"metadata":{"id":"6zYNGonnZzlZ"}},{"cell_type":"code","source":["transcripcion_modelo_1 = transcribe_audio(client, \"audio_1.m4a\", \"whisper-1\")\n","transcripcion_modelo_1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zxuu-rmkZy-A","executionInfo":{"status":"ok","timestamp":1717524311414,"user_tz":-120,"elapsed":1659,"user":{"displayName":"Arturo SP","userId":"07770316912620247459"}},"outputId":"db7583bb-94f4-42d0-8fef-2acd88f1d4af"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Transcription(text='OpenAI es una empresa de investigación y despliegue de inteligencia artificial, fundada en 2015 e inicialmente sin ánimo de lucro. Su misión original era asegurar que la inteligencia artificial general fuese desarrollada como código libre y en beneficio de toda la humanidad.')"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["Para trabajar con otros modelos no podemos recurrir a la API y necesitamos instalarnos las herramientas Open Source de OpenAI:"],"metadata":{"id":"pw4c8947aVtg"}},{"cell_type":"code","source":["!pip install git+https://github.com/openai/whisper.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qy6i5DQjaGt5","executionInfo":{"status":"ok","timestamp":1717524428342,"user_tz":-120,"elapsed":89719,"user":{"displayName":"Arturo SP","userId":"07770316912620247459"}},"outputId":"5840cd9a-10b4-45a3-fb9b-56a45bad1742"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/openai/whisper.git\n","  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-bbsddofv\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-bbsddofv\n","  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.25.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.0+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.4)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n","Collecting tiktoken (from openai-whisper==20231117)\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.14.0)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2024.5.15)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.12.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n","Building wheels for collected packages: openai-whisper\n","  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802826 sha256=a233f3bdafcdc34474403698a3174fa4f9d0b604e98cd160b219707656702605\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-zbgeyqd_/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n","Successfully built openai-whisper\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 openai-whisper-20231117 tiktoken-0.7.0\n"]}]},{"cell_type":"markdown","source":["Además necesitamos algunas herramientas extra para el tratamiento de audio:"],"metadata":{"id":"4U-XSI7Gajm2"}},{"cell_type":"code","source":["!sudo apt update && sudo apt install ffmpeg"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iOAnf78GagxY","executionInfo":{"status":"ok","timestamp":1717524466020,"user_tz":-120,"elapsed":18780,"user":{"displayName":"Arturo SP","userId":"07770316912620247459"}},"outputId":"ef310b31-144c-42a9-de1d-e50b85f683db"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n","\u001b[33m\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\u001b[0m\u001b[33m\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\u001b[0m\r                                                                               \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n","Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [891 kB]\n","Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","Get:7 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,858 kB]\n","Hit:8 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n","Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,085 kB]\n","Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,129 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,378 kB]\n","Fetched 7,603 kB in 14s (560 kB/s)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","46 packages can be upgraded. Run 'apt list --upgradable' to see them.\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n","0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\n"]}]},{"cell_type":"markdown","source":["Tras la instalación importamos los paquetes necesarios:"],"metadata":{"id":"tNfBpcB7auYL"}},{"cell_type":"code","source":["import os\n","import whisper\n","import time"],"metadata":{"id":"r2UU0LdxawmC","executionInfo":{"status":"ok","timestamp":1717524487056,"user_tz":-120,"elapsed":4194,"user":{"displayName":"Arturo SP","userId":"07770316912620247459"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["Vamos a probar a usar el modelo más pequeño `tiny`.\n","\n","Para ello empezamos cargando el modelo:"],"metadata":{"id":"pB6l9wURa5d0"}},{"cell_type":"code","source":["model = whisper.load_model(\"tiny\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PYS4mDPXa0g3","executionInfo":{"status":"ok","timestamp":1717524496343,"user_tz":-120,"elapsed":1979,"user":{"displayName":"Arturo SP","userId":"07770316912620247459"}},"outputId":"eb55cc25-68b5-4886-9f89-2fcf9b2698ea"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████████████████████████████████| 72.1M/72.1M [00:00<00:00, 106MiB/s]\n"]}]},{"cell_type":"markdown","source":["Una vez hecho esto procedemos a lanzar nuestra transcripción:"],"metadata":{"id":"6vOBM4tdbLOQ"}},{"cell_type":"code","source":["inicio = time.time()\n","resultado_tiny = model.transcribe(\"audio_1.m4a\")\n","fin = time.time()\n","print(\"Tarda\", fin-inicio, \"segundos.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7d4FvRHHa0jK","executionInfo":{"status":"ok","timestamp":1717524516854,"user_tz":-120,"elapsed":5810,"user":{"displayName":"Arturo SP","userId":"07770316912620247459"}},"outputId":"a6be71cf-6fee-499d-fa3a-a8d9dd3e152e"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n","  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"]},{"output_type":"stream","name":"stdout","text":["Tarda 5.561684608459473 segundos.\n"]}]},{"cell_type":"code","source":["resultado_tiny"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ph7L4G3a0lx","executionInfo":{"status":"ok","timestamp":1717524522798,"user_tz":-120,"elapsed":279,"user":{"displayName":"Arturo SP","userId":"07770316912620247459"}},"outputId":"5551cec6-f299-4361-807b-e1cd12275a95"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'text': ' O PNAI es una empresa de investigación y despliedad interligencia artificial. Fondada en 2015 inicialmente sin ánimo del upro. Su misión original era asegurar que la interligencia artificial general fue se desarrollada como código libre y en beneficio de toda la humanidad.',\n"," 'segments': [{'id': 0,\n","   'seek': 0,\n","   'start': 0.0,\n","   'end': 8.0,\n","   'text': ' O PNAI es una empresa de investigación y despliedad interligencia artificial. Fondada en 2015',\n","   'tokens': [50364,\n","    422,\n","    430,\n","    5321,\n","    40,\n","    785,\n","    2002,\n","    22682,\n","    368,\n","    48919,\n","    288,\n","    730,\n","    564,\n","    1091,\n","    345,\n","    728,\n","    5073,\n","    10974,\n","    11677,\n","    13,\n","    479,\n","    684,\n","    1538,\n","    465,\n","    7546,\n","    50764],\n","   'temperature': 0.0,\n","   'avg_logprob': -0.42127005259195965,\n","   'compression_ratio': 1.4427083333333333,\n","   'no_speech_prob': 0.07110998034477234},\n","  {'id': 1,\n","   'seek': 0,\n","   'start': 8.0,\n","   'end': 14.0,\n","   'text': ' inicialmente sin ánimo del upro. Su misión original era asegurar que la interligencia artificial general',\n","   'tokens': [50764,\n","    44076,\n","    4082,\n","    3343,\n","    7352,\n","    77,\n","    6934,\n","    1103,\n","    493,\n","    340,\n","    13,\n","    2746,\n","    3346,\n","    2560,\n","    3380,\n","    4249,\n","    38174,\n","    28586,\n","    631,\n","    635,\n","    728,\n","    5073,\n","    10974,\n","    11677,\n","    2674,\n","    51064],\n","   'temperature': 0.0,\n","   'avg_logprob': -0.42127005259195965,\n","   'compression_ratio': 1.4427083333333333,\n","   'no_speech_prob': 0.07110998034477234},\n","  {'id': 2,\n","   'seek': 0,\n","   'start': 14.0,\n","   'end': 18.0,\n","   'text': ' fue se desarrollada como código libre y en beneficio de toda la humanidad.',\n","   'tokens': [51064,\n","    9248,\n","    369,\n","    32501,\n","    1538,\n","    2617,\n","    44195,\n","    29976,\n","    288,\n","    465,\n","    10304,\n","    1004,\n","    368,\n","    11687,\n","    635,\n","    1952,\n","    4580,\n","    13,\n","    51264],\n","   'temperature': 0.0,\n","   'avg_logprob': -0.42127005259195965,\n","   'compression_ratio': 1.4427083333333333,\n","   'no_speech_prob': 0.07110998034477234}],\n"," 'language': 'es'}"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["Podemos ver que los resultados no son muy buenos. Probemos ahora a realizar la misma transcripción con un modelo más potente:"],"metadata":{"id":"273Kc61HbpbX"}},{"cell_type":"code","source":["model_large = whisper.load_model(\"large-v2\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dGIPRY3EbyIa","executionInfo":{"status":"ok","timestamp":1717524745666,"user_tz":-120,"elapsed":143042,"user":{"displayName":"Arturo SP","userId":"07770316912620247459"}},"outputId":"11ae0830-268b-4fa2-9354-6694a17c8846"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|█████████████████████████████████████| 2.87G/2.87G [01:41<00:00, 30.5MiB/s]\n"]}]},{"cell_type":"markdown","source":["__Nota.__ Observamos que solo la carga del modelo ya lleva mucho más tiempo. Si abrimos el panel de consumo podemos ver cómo el uso de RAM se dispara."],"metadata":{"id":"YkwVgWUSb5KH"}},{"cell_type":"code","source":["inicio = time.time()\n","resultado_large = model_large.transcribe(\"audio_1.m4a\")\n","fin = time.time()\n","print(\"Tarda\", fin-inicio, \"segundos.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GsM6pVCqb2kO","executionInfo":{"status":"ok","timestamp":1717524904177,"user_tz":-120,"elapsed":131276,"user":{"displayName":"Arturo SP","userId":"07770316912620247459"}},"outputId":"ffb27820-19de-4d4b-ed96-76e086e76275"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n","  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"]},{"output_type":"stream","name":"stdout","text":["Tarda 130.44068884849548 segundos.\n"]}]},{"cell_type":"code","source":["resultado_large"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qcg-DG3HcgNX","executionInfo":{"status":"ok","timestamp":1717524923637,"user_tz":-120,"elapsed":410,"user":{"displayName":"Arturo SP","userId":"07770316912620247459"}},"outputId":"95f24e2a-005b-4d63-bd0f-4b7e4f193e33"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'text': ' OpenAI es una empresa de investigación y despliegue de inteligencia artificial, fundada en 2015 e inicialmente sin ánimo de lucro. Su misión original era asegurar que la inteligencia artificial general fuese desarrollada como código libre y en beneficio de toda la humanidad.',\n"," 'segments': [{'id': 0,\n","   'seek': 0,\n","   'start': 0.0,\n","   'end': 7.08,\n","   'text': ' OpenAI es una empresa de investigación y despliegue de inteligencia artificial, fundada',\n","   'tokens': [50364,\n","    7238,\n","    48698,\n","    785,\n","    2002,\n","    22682,\n","    368,\n","    48919,\n","    288,\n","    730,\n","    564,\n","    414,\n","    11929,\n","    368,\n","    24777,\n","    3213,\n","    2755,\n","    11677,\n","    11,\n","    2374,\n","    1538,\n","    50718],\n","   'temperature': 0.0,\n","   'avg_logprob': -0.23869334181694135,\n","   'compression_ratio': 1.4607329842931938,\n","   'no_speech_prob': 0.036072004586458206},\n","  {'id': 1,\n","   'seek': 0,\n","   'start': 7.08,\n","   'end': 10.4,\n","   'text': ' en 2015 e inicialmente sin ánimo de lucro.',\n","   'tokens': [50718,\n","    465,\n","    7546,\n","    308,\n","    44076,\n","    4082,\n","    3343,\n","    7352,\n","    77,\n","    6934,\n","    368,\n","    21296,\n","    340,\n","    13,\n","    50884],\n","   'temperature': 0.0,\n","   'avg_logprob': -0.23869334181694135,\n","   'compression_ratio': 1.4607329842931938,\n","   'no_speech_prob': 0.036072004586458206},\n","  {'id': 2,\n","   'seek': 0,\n","   'start': 10.4,\n","   'end': 15.48,\n","   'text': ' Su misión original era asegurar que la inteligencia artificial general fuese desarrollada como',\n","   'tokens': [50884,\n","    2746,\n","    3346,\n","    2560,\n","    3380,\n","    4249,\n","    38174,\n","    28586,\n","    631,\n","    635,\n","    24777,\n","    3213,\n","    2755,\n","    11677,\n","    2674,\n","    8536,\n","    1130,\n","    32501,\n","    1538,\n","    2617,\n","    51138],\n","   'temperature': 0.0,\n","   'avg_logprob': -0.23869334181694135,\n","   'compression_ratio': 1.4607329842931938,\n","   'no_speech_prob': 0.036072004586458206},\n","  {'id': 3,\n","   'seek': 0,\n","   'start': 15.48,\n","   'end': 17.88,\n","   'text': ' código libre y en beneficio de toda la humanidad.',\n","   'tokens': [51138,\n","    44195,\n","    29976,\n","    288,\n","    465,\n","    10304,\n","    1004,\n","    368,\n","    11687,\n","    635,\n","    1952,\n","    4580,\n","    13,\n","    51258],\n","   'temperature': 0.0,\n","   'avg_logprob': -0.23869334181694135,\n","   'compression_ratio': 1.4607329842931938,\n","   'no_speech_prob': 0.036072004586458206}],\n"," 'language': 'es'}"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["Observamos que los resultados son más adecuados pero el consumo de recursos y tiempo ha sido mucho más alto."],"metadata":{"id":"9w25kiL0ciqX"}},{"cell_type":"markdown","source":["## Generación de subtítulos\n","\n","Por último veamos cómo Whisper cuenta con herramientas para transcribir los audios a distintos formatos:"],"metadata":{"id":"kYSJHC5VcBFt"}},{"cell_type":"code","source":["from whisper.utils import WriteTXT, WriteSRT, WriteVTT"],"metadata":{"id":"LdLbKOPEa0oY","executionInfo":{"status":"ok","timestamp":1717525035657,"user_tz":-120,"elapsed":299,"user":{"displayName":"Arturo SP","userId":"07770316912620247459"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["Estas utilidades nos permiten escribir archivos `.txt`, `SRT`y `VTT`. Veamos cómo su uso es terriblemente sencillo.\n","\n","Creamos una carpeta llamada resultados donde almacenar las salidas y tras ello simplemente utilizamos estos métodos:"],"metadata":{"id":"lf279AQ7cwxh"}},{"cell_type":"code","source":["carpeta_resultados = \"resultados\"\n","if not os.path.exists(carpeta_resultados):\n","    os.makedirs(carpeta_resultados)\n","\n","# Crear instancias de las clases para escribir los resultados\n","write_txt = WriteTXT(carpeta_resultados)\n","write_srt = WriteSRT(carpeta_resultados)\n","write_vtt = WriteVTT(carpeta_resultados)\n","\n","# Escribir la transcripción en un archivo TXT\n","write_txt(resultado_large, \"audio_1.m4a\")\n","\n","# Escribir los subtítulos en archivos SRT y VTT\n","write_srt(resultado_large, \"audio_1.m4a\")\n","write_vtt(resultado_large, \"audio_1.m4a\")"],"metadata":{"id":"06AkncUgdBNi","executionInfo":{"status":"ok","timestamp":1717525063102,"user_tz":-120,"elapsed":415,"user":{"displayName":"Arturo SP","userId":"07770316912620247459"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["Podemos observar que los archivos se han generado y almacenado de forma correcta.\n","\n","## Cierre\n","\n","En este cuaderno hemos visto como con unas pocas líneas hemos conseguido cargar los modelos de OpenAI para su consumo de manera gratuita y hemos inferido sobre un audio generando desde una transcripción pura a un archivo de subtítulos. Esto nos permite el desarrollo de una gran cantidad de aplicaciones y usos. Os animos a probar con vuestros propios audios y a experimentar como los distintos modelos procesan cosas como los ruidos de fondo o los distintos acentos y tipos de pronunciación."],"metadata":{"id":"GSlryZlDdscG"}}]}