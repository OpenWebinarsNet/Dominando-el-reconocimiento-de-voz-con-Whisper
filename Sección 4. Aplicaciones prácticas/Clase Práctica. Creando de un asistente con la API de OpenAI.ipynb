{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOwB7eoHN4D3buHWgt4bqjy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Creando nuestro primer Thread\n","\n","En esta práctica vamos a ver:\n","\n","* ¿Cómo crear un objeto Assistant desde Python?\n","* ¿Cómo construir un Thread sobre este objeto?\n","* ¿Cómo añadir mensajes a un Thread?\n","\n","Para ello empezamos instalando e importando el módulo de OpenAI:"],"metadata":{"id":"ioHyzrHL7Xpg"}},{"cell_type":"markdown","source":["## Configuración del entorno"],"metadata":{"id":"MoTw6knR9RbP"}},{"cell_type":"code","source":["!pip install openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KOVGbbzT7YDT","executionInfo":{"status":"ok","timestamp":1717683192313,"user_tz":-120,"elapsed":16337,"user":{"displayName":"Arturo SP","userId":"07770316912620247459"}},"outputId":"0b6f23a4-1f9e-46e2-c80c-8242e71ffa84"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openai\n","  Downloading openai-1.31.1-py3-none-any.whl (324 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/324.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/324.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m317.4/324.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.1/324.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Collecting httpx<1,>=0.23.0 (from openai)\n","  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.3)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n","  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n","Installing collected packages: h11, httpcore, httpx, openai\n","Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.31.1\n"]}]},{"cell_type":"code","source":["import openai\n","client = openai.OpenAI()"],"metadata":{"id":"r9CKEKSF9EeY","executionInfo":{"status":"ok","timestamp":1717683225289,"user_tz":-120,"elapsed":232,"user":{"displayName":"Arturo SP","userId":"07770316912620247459"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["Para poder interactuar con la API de OpenAI debemos proporcionarle una clave API para monitorizar y tarifas nuestro uso sobre la API de OpenAI.\n","\n","Almacenamos nuestra clave API en una variable de entorno:"],"metadata":{"id":"Squp4E9y8P9v"}},{"cell_type":"code","source":["import os\n","os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-JgnyPrVpPr4xoz1FrPxiT3BlbkFJcIB6dz6ptu7gA5UifDsQ\""],"metadata":{"id":"7bW_8f288MrU","executionInfo":{"status":"ok","timestamp":1717683212214,"user_tz":-120,"elapsed":249,"user":{"displayName":"Arturo SP","userId":"07770316912620247459"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Ejecutando la siguiente celda puedes comprobar que tu variable de entorno se haya generado de manera correcta:"],"metadata":{"id":"z-b2HkqU8vG9"}},{"cell_type":"code","source":["print(os.environ[\"OPENAI_API_KEY\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gGDum9ZG8rho","executionInfo":{"status":"ok","timestamp":1717683216546,"user_tz":-120,"elapsed":233,"user":{"displayName":"Arturo SP","userId":"07770316912620247459"}},"outputId":"ccd3b634-2a30-46c3-a005-a02bc6d5d94d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["sk-proj-JgnyPrVpPr4xoz1FrPxiT3BlbkFJcIB6dz6ptu7gA5UifDsQ\n"]}]},{"cell_type":"markdown","source":["A continuación, establecemos esta variable como la clave a la que acudirá OpenAI para validar nuestras llamadas:"],"metadata":{"id":"au8ch3_d8-xQ"}},{"cell_type":"code","source":["openai.api_key = os.environ[\"OPENAI_API_KEY\"]"],"metadata":{"id":"C8A3x93a8xU6","executionInfo":{"status":"ok","timestamp":1717683219788,"user_tz":-120,"elapsed":279,"user":{"displayName":"Arturo SP","userId":"07770316912620247459"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Creación del asistente\n","\n","Comenzamos construyendo nuestro prompt para la creación del asistente:"],"metadata":{"id":"0unL1wuR9QEj"}},{"cell_type":"code","source":["instrucciones_asistente = \"\"\"\n","Eres un profesor de inglés. Los usuarios te plantearán una situación para simular una conversación en inglés. Tú haras un rol y el usuario el otro.\n","Si el usuario te envía mensajes con errores ortográficos explícale los errores y dile cómo se diría correctamente. Cuando simules situaciones solo hablarás en inglés.\n","\"\"\""],"metadata":{"id":"fs8w95iy9tpF","executionInfo":{"status":"ok","timestamp":1717683309118,"user_tz":-120,"elapsed":256,"user":{"displayName":"Arturo SP","userId":"07770316912620247459"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["Procedemos a crear nuestro primer asistente:"],"metadata":{"id":"1qkeSbFB9inq"}},{"cell_type":"code","source":["assistant = client.beta.assistants.create(\n","  name=\"Profesor de Inglés\",\n","  instructions=instrucciones_asistente,\n","  model=\"gpt-4o\",\n",")"],"metadata":{"id":"5FFHe2ic9BgT","executionInfo":{"status":"ok","timestamp":1717683355267,"user_tz":-120,"elapsed":615,"user":{"displayName":"Arturo SP","userId":"07770316912620247459"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["assistant"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0DlW8EvGFzHt","executionInfo":{"status":"ok","timestamp":1717683361058,"user_tz":-120,"elapsed":344,"user":{"displayName":"Arturo SP","userId":"07770316912620247459"}},"outputId":"f12b9e86-1e36-4c69-d6f0-d1fd3117d558"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Assistant(id='asst_wOcPED5Wz6tPAOf5zovmPuwf', created_at=1717683354, description=None, instructions='\\nEres un profesor de inglés. Los usuarios te plantearán una situación para simular una conversación en inglés. Tú haras un rol y el usuario el otro.\\nSi el usuario te envía mensajes con errores ortográficos explícale los errores y dile cómo se diría correctamente. Cuando simules situaciones solo hablarás en inglés.\\n', metadata={}, model='gpt-4o', name='Profesor de Inglés', object='assistant', tools=[], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=None, file_search=None), top_p=1.0)"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["Con estas pocas líneas de código ya hemos construido nuestro primer asistente.\n","\n","Si visitamos la API de OpenAI podemos ver cómo este asisnte existe en nuestra lista de asistentes. Echémosle un ojo y comencemos a probarlo."],"metadata":{"id":"j2IJEMjw-q_C"}},{"cell_type":"markdown","source":["## Trabajando con los Threads y los Messages\n","\n","\n","Al realizar esta interacción con nuestro asistente hemos generado un primer hilo cuyo nombre aparece arriba a la izquierda en la conversación.\n","\n","Vamos a recuperar la información del hilo desde Python:"],"metadata":{"id":"IwF9R3SK_n-4"}},{"cell_type":"code","source":["hilo = \"thread_1YhCcIKRMcAIt8Yarxw017GI\"\n","mi_hilo = client.beta.threads.retrieve(hilo)\n","print(mi_hilo)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yrh_iVRf-Wou","executionInfo":{"status":"ok","timestamp":1717683654297,"user_tz":-120,"elapsed":870,"user":{"displayName":"Arturo SP","userId":"07770316912620247459"}},"outputId":"06a29bd0-52d6-4d6b-fa1a-a328bbccba35"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Thread(id='thread_1YhCcIKRMcAIt8Yarxw017GI', created_at=1717683502, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=ToolResourcesCodeInterpreter(file_ids=[]), file_search=None))\n"]}]},{"cell_type":"markdown","source":["También es posible recuperar la información de los mensajes:"],"metadata":{"id":"AK1HryJIBPIP"}},{"cell_type":"code","source":["mensajes_hilo = client.beta.threads.messages.list(hilo)\n","print(mensajes_hilo.data)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_gF3KKPMAvHP","executionInfo":{"status":"ok","timestamp":1717683673297,"user_tz":-120,"elapsed":617,"user":{"displayName":"Arturo SP","userId":"07770316912620247459"}},"outputId":"ed40c576-cbaa-4d1b-ae38-2d0942358431"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["[Message(id='msg_3g7JZEKXnMWApSaBgtZZgAON', assistant_id='asst_wOcPED5Wz6tPAOf5zovmPuwf', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='There was a small mistake in your sentence. Instead of \"I doesn\\'t know yet,\" it should be \"I don\\'t know yet.\"\\n\\n**Salesperson:** I see. No worries, I can help you with that. Do you have a preference for any particular brand, or are there any specific features you are looking for in a laptop?'), type='text')], created_at=1717683550, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_mvD6zkiSA58frFIKJYQyANgC', status=None, thread_id='thread_1YhCcIKRMcAIt8Yarxw017GI'), Message(id='msg_Sj6ViZQfYyuDFx0bTQluLzjI', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value=\"I doesn't know yet!\"), type='text')], created_at=1717683549, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_1YhCcIKRMcAIt8Yarxw017GI'), Message(id='msg_VNK6g835kBZSYUbuEGAZg0Kv', assistant_id='asst_wOcPED5Wz6tPAOf5zovmPuwf', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='**Salesperson:** Great! We have a wide range of laptops. What will you be using the laptop for mostly? Are you looking for something for work, gaming, or general use?'), type='text')], created_at=1717683532, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_w1i3fpLEuexy4wjnsFNMDYP8', status=None, thread_id='thread_1YhCcIKRMcAIt8Yarxw017GI'), Message(id='msg_oP7oC4R2pX4q3D9LeUOCCY2E', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='I want to buy a laptop'), type='text')], created_at=1717683531, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_1YhCcIKRMcAIt8Yarxw017GI'), Message(id='msg_UgjVxLPnXChCEqgiCX9kjdxP', assistant_id='asst_wOcPED5Wz6tPAOf5zovmPuwf', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value=\"Of course! Let's start the simulation.\\n\\n**Salesperson:** Good afternoon! Welcome to our store. How can I help you today?\"), type='text')], created_at=1717683505, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_YdCbDP9GoJKMOwtZr53B1kXb', status=None, thread_id='thread_1YhCcIKRMcAIt8Yarxw017GI'), Message(id='msg_9qPVytYwf7JnQCAKTpaQFvpF', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='Hola, quiero simular que voy a una tienda a comprar un ordenador'), type='text')], created_at=1717683503, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_1YhCcIKRMcAIt8Yarxw017GI')]\n"]}]},{"cell_type":"markdown","source":["Los mensajes se recuperan de presente a pasado, es decir, el primer elemento de la lista de mensajes será el último mensaje enviado. Vamos a construir una función para reconstruir la conversación:"],"metadata":{"id":"OXZLQ1sqCWat"}},{"cell_type":"code","source":["def recupera_conversacion_de_hilo(hilo):\n","  conversacion = {}\n","  mensajes_hilo = client.beta.threads.messages.list(hilo)\n","  longitud_hilo = len(mensajes_hilo.data)\n","  for indice in range(0, longitud_hilo):\n","    informacion_mensaje = mensajes_hilo.data[longitud_hilo-1-indice]\n","    conversacion[indice] = (informacion_mensaje.role, informacion_mensaje.content[0].text.value)\n","\n","  return conversacion\n","\n"],"metadata":{"id":"FNRF5QDZChqP","executionInfo":{"status":"ok","timestamp":1717683735408,"user_tz":-120,"elapsed":2,"user":{"displayName":"Arturo SP","userId":"07770316912620247459"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["conversacion_hilo = recupera_conversacion_de_hilo(hilo)\n","conversacion_hilo"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7wI_S9TeED9t","executionInfo":{"status":"ok","timestamp":1717683737453,"user_tz":-120,"elapsed":466,"user":{"displayName":"Arturo SP","userId":"07770316912620247459"}},"outputId":"14a49232-81fb-4d13-a408-2f50b9796d43"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: ('user',\n","  'Hola, quiero simular que voy a una tienda a comprar un ordenador'),\n"," 1: ('assistant',\n","  \"Of course! Let's start the simulation.\\n\\n**Salesperson:** Good afternoon! Welcome to our store. How can I help you today?\"),\n"," 2: ('user', 'I want to buy a laptop'),\n"," 3: ('assistant',\n","  '**Salesperson:** Great! We have a wide range of laptops. What will you be using the laptop for mostly? Are you looking for something for work, gaming, or general use?'),\n"," 4: ('user', \"I doesn't know yet!\"),\n"," 5: ('assistant',\n","  'There was a small mistake in your sentence. Instead of \"I doesn\\'t know yet,\" it should be \"I don\\'t know yet.\"\\n\\n**Salesperson:** I see. No worries, I can help you with that. Do you have a preference for any particular brand, or are there any specific features you are looking for in a laptop?')}"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["También podemos realizar la operación complementaria y añadir mensajes a un hilo desde Python:"],"metadata":{"id":"xCcil2r7E4Cc"}},{"cell_type":"code","source":["thread_message = client.beta.threads.messages.create(\n","  hilo,\n","  role=\"user\",\n","  content=\"I love Apple computers\",\n",")\n","print(thread_message)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"18vvKifEE86K","executionInfo":{"status":"ok","timestamp":1717683794722,"user_tz":-120,"elapsed":329,"user":{"displayName":"Arturo SP","userId":"07770316912620247459"}},"outputId":"080501ed-89d5-45ad-89ed-64f7bccc4b01"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Message(id='msg_zYhFk2Gl6nHfgYf46hlysveJ', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='I love Apple computers'), type='text')], created_at=1717683794, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_1YhCcIKRMcAIt8Yarxw017GI')\n"]}]},{"cell_type":"markdown","source":["Si volvemos a la pantalla de OpenAI de nuestro asistente podemos ver cómo aparece el mensaje."],"metadata":{"id":"M9ThEjclFWAr"}},{"cell_type":"code","source":["conversacion_hilo_1 = recupera_conversacion_de_hilo(hilo)\n","conversacion_hilo_1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hn4rhnq6Ff6Q","executionInfo":{"status":"ok","timestamp":1717683804217,"user_tz":-120,"elapsed":411,"user":{"displayName":"Arturo SP","userId":"07770316912620247459"}},"outputId":"3bee4230-3db4-4854-8f13-5942b5db6470"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: ('user',\n","  'Hola, quiero simular que voy a una tienda a comprar un ordenador'),\n"," 1: ('assistant',\n","  \"Of course! Let's start the simulation.\\n\\n**Salesperson:** Good afternoon! Welcome to our store. How can I help you today?\"),\n"," 2: ('user', 'I want to buy a laptop'),\n"," 3: ('assistant',\n","  '**Salesperson:** Great! We have a wide range of laptops. What will you be using the laptop for mostly? Are you looking for something for work, gaming, or general use?'),\n"," 4: ('user', \"I doesn't know yet!\"),\n"," 5: ('assistant',\n","  'There was a small mistake in your sentence. Instead of \"I doesn\\'t know yet,\" it should be \"I don\\'t know yet.\"\\n\\n**Salesperson:** I see. No worries, I can help you with that. Do you have a preference for any particular brand, or are there any specific features you are looking for in a laptop?'),\n"," 6: ('user', 'I love Apple computers')}"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["Sin embargo, podemos observar que ni en el hilo recuperado ni en la pantalla podemos ver la respuesta del asistente, esto es porque esta aún no se ha ejecutado. Para ello deberíamos disparar la ejecución desde el siguiente comando:"],"metadata":{"id":"iIlwGZ3fGPcP"}},{"cell_type":"code","source":["run = client.beta.threads.runs.create(\n","  thread_id=hilo,\n","  assistant_id=assistant.id\n",")\n","\n","print(run)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GEsCdUR7FtQp","executionInfo":{"status":"ok","timestamp":1717683822452,"user_tz":-120,"elapsed":826,"user":{"displayName":"Arturo SP","userId":"07770316912620247459"}},"outputId":"0f4b48e8-6926-4753-fc7c-24927084fca8"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Run(id='run_lMFd8ocZtWp6IqMdrAfU0fR7', assistant_id='asst_wOcPED5Wz6tPAOf5zovmPuwf', cancelled_at=None, completed_at=None, created_at=1717683821, expires_at=1717684421, failed_at=None, incomplete_details=None, instructions='\\nEres un profesor de inglés. Los usuarios te plantearán una situación para simular una conversación en inglés. Tú haras un rol y el usuario el otro.\\nSi el usuario te envía mensajes con errores ortográficos explícale los errores y dile cómo se diría correctamente. Cuando simules situaciones solo hablarás en inglés.\\n', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-4o', object='thread.run', required_action=None, response_format='auto', started_at=None, status='queued', thread_id='thread_1YhCcIKRMcAIt8Yarxw017GI', tool_choice='auto', tools=[], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=None, temperature=1.0, top_p=1.0, tool_resources={})\n"]}]},{"cell_type":"markdown","source":["Al mirar ahora en la pantalla sí que tendremos nuestra respuesta, al igual que si recuperamos el hilo. Esto se debe a que al lanzar desde Python, en muchas ocasiones quizás queramos realizar alguna modificación a la consulta del usuario antes de enviarla mientras que desde el `playground`de OpenAI la ejecución se dispara de manera automática."],"metadata":{"id":"1nLqSfpMGar0"}},{"cell_type":"code","source":["conversacion_hilo_2 = recupera_conversacion_de_hilo(hilo)\n","conversacion_hilo_2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JwAiz3SYFtS_","executionInfo":{"status":"ok","timestamp":1717683848250,"user_tz":-120,"elapsed":276,"user":{"displayName":"Arturo SP","userId":"07770316912620247459"}},"outputId":"9ac4ef2d-b304-40cf-a5ba-636d1c47407c"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: ('user',\n","  'Hola, quiero simular que voy a una tienda a comprar un ordenador'),\n"," 1: ('assistant',\n","  \"Of course! Let's start the simulation.\\n\\n**Salesperson:** Good afternoon! Welcome to our store. How can I help you today?\"),\n"," 2: ('user', 'I want to buy a laptop'),\n"," 3: ('assistant',\n","  '**Salesperson:** Great! We have a wide range of laptops. What will you be using the laptop for mostly? Are you looking for something for work, gaming, or general use?'),\n"," 4: ('user', \"I doesn't know yet!\"),\n"," 5: ('assistant',\n","  'There was a small mistake in your sentence. Instead of \"I doesn\\'t know yet,\" it should be \"I don\\'t know yet.\"\\n\\n**Salesperson:** I see. No worries, I can help you with that. Do you have a preference for any particular brand, or are there any specific features you are looking for in a laptop?'),\n"," 6: ('user', 'I love Apple computers'),\n"," 7: ('assistant',\n","  '**Salesperson:** Excellent choice! Apple laptops are known for their performance and design. We have several models of MacBooks. Are you interested in the MacBook Air or the MacBook Pro?')}"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["## Cierre\n","\n","Con unas pocas líneas de código hemos conseguido desplegar nuestro propio asistente capaz de simular conversaciones para ayudarnos a mejorar nuestra fluidez en inglés. Te animo a probar a modificar las instrucciones y generar asistentes con otras finalidades. Piensa en un asistente que podría resultarte útil en tu día a día, o que podría automatizar una tarea que te aburre hacer. Las posibilidades gracias a GPT son prácticamente ilimitadas. No dudes en dejar en comentarios las ideas que se te han ido ocurriendo."],"metadata":{"id":"hxUrG6wyG2e-"}}]}